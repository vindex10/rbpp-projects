{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "In this chapter we are going to train few simple classifiers, discover issues specific to the dataset, present several ways to target them in future model developments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.ensemble import EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "data_path = \"/afs/cern.ch/user/a/ananiev/cernbox/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(data_path, \"hgg_features.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's look at the event counts, and how the weights are distributed among these events:\n",
    "\n",
    "* **event_num** — number of events per process\n",
    "* **weight_sums** — sum of weights per process\n",
    "* **weight_frac** — fraction of weights per process normalized to the total weight of all events\n",
    "* **weight_per_event** — average weight of event within the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_num</th>\n",
       "      <th>weight_sums</th>\n",
       "      <th>weight_frac</th>\n",
       "      <th>weight_per_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VBF</th>\n",
       "      <td>10369</td>\n",
       "      <td>9.612055e-05</td>\n",
       "      <td>0.064293</td>\n",
       "      <td>9.269992e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wp</th>\n",
       "      <td>2112</td>\n",
       "      <td>1.702021e-05</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>8.058813e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>4571</td>\n",
       "      <td>1.697019e-05</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>3.712578e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gg</th>\n",
       "      <td>26258</td>\n",
       "      <td>1.364896e-03</td>\n",
       "      <td>0.912952</td>\n",
       "      <td>5.198020e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt</th>\n",
       "      <td>9861</td>\n",
       "      <td>2.851057e-08</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>2.891245e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     event_num   weight_sums  weight_frac  weight_per_event\n",
       "VBF      10369  9.612055e-05     0.064293      9.269992e-09\n",
       "Wp        2112  1.702021e-05     0.011384      8.058813e-09\n",
       "Z         4571  1.697019e-05     0.011351      3.712578e-09\n",
       "gg       26258  1.364896e-03     0.912952      5.198020e-08\n",
       "tt        9861  2.851057e-08     0.000019      2.891245e-12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weight_descriptive(data):\n",
    "    res = {}\n",
    "    \n",
    "    event_counts = data[\"label\"].value_counts().sort_values(ascending=False)\n",
    "    res[\"event_num\"] = event_counts\n",
    "    \n",
    "    weight_sums = data.groupby(\"label\")[\"weight\"].sum().sort_values(ascending=False)\n",
    "    res[\"weight_sums\"] = weight_sums\n",
    "    \n",
    "    weight_frac = weight_sums/data[\"weight\"].sum()\n",
    "    res[\"weight_frac\"] = weight_frac\n",
    "    \n",
    "    weight_per_event = weight_sums/event_counts\n",
    "    res[\"weight_per_event\"] = weight_per_event\n",
    "    \n",
    "    return pd.DataFrame(res)\n",
    "weight_descriptive(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "\n",
    "* **tt** events are not a lot, and they have relatively small weight\n",
    "* **Wp**, **Z** are quite few, but the weight is significant\n",
    "* **VBF** are quite a lot and the weight is mediocre\n",
    "* **gg** are the decent majority, while their weight is quite small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we list features we can use during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['photon_n', 'photon_1lead_pt', 'photon_1lead_eta', 'photon_1lead_phi',\n",
       "       'photon_1lead_E', 'photon_1lead_etcone20', 'photon_2lead_pt',\n",
       "       'photon_2lead_eta', 'photon_2lead_phi', 'photon_2lead_E',\n",
       "       'photon_2lead_etcone20', 'h_mass', 'lep_n', 'lep_pt_min', 'lep_pt_max',\n",
       "       'lep_pt_mean', 'lep_pt_sum', 'lep_pt_std', 'lep_phi_min', 'lep_phi_max',\n",
       "       'lep_phi_mean', 'lep_phi_sum', 'lep_phi_std', 'lep_E_min', 'lep_E_max',\n",
       "       'lep_E_mean', 'lep_E_sum', 'lep_E_std', 'lep_theta_min',\n",
       "       'lep_theta_max', 'lep_theta_mean', 'lep_theta_sum', 'lep_theta_std',\n",
       "       'lep_charge_min', 'lep_charge_max', 'lep_charge_mean', 'lep_charge_sum',\n",
       "       'lep_charge_std', 'lep_z0_min', 'lep_z0_max', 'lep_z0_mean',\n",
       "       'lep_z0_sum', 'lep_z0_std', 'lep_ptcone30_min', 'lep_ptcone30_max',\n",
       "       'lep_ptcone30_mean', 'lep_ptcone30_sum', 'lep_ptcone30_std',\n",
       "       'lep_etcone20_min', 'lep_etcone20_max', 'lep_etcone20_mean',\n",
       "       'lep_etcone20_sum', 'lep_etcone20_std', 'weight', 'met_et', 'met_phi',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train baseline model with ensemble of trees in order to identify at least somewhat relevant features to the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def train_test_val_split(dataset, target, test_size, val_size, *args, **kwargs):\n",
    "    shuffle = kwargs.get(\"shuffle\", True)\n",
    "    del kwargs[\"shuffle\"]\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(data.drop(columns=[target]), data[target], *args, test_size=test_size, shuffle=shuffle, **kwargs)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_size, shuffle=False, **kwargs)\n",
    "    return (pd.concat([X_train, y_train], axis=\"columns\"),\n",
    "            pd.concat([X_val, y_val], axis=\"columns\"),\n",
    "            pd.concat([X_test, y_test], axis=\"columns\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split dataset into training, validation and test samples. Test sample constitute 20% of the data, while validation sample is 8%. Rest 72% are training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train, d_val, d_test = train_test_val_split(data, \"label\", 0.2, 0.1, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "class KeepFeatures(TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X[self.features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "class FillNa(TransformerMixin):\n",
    "    def __init__(self, mapping):\n",
    "        if isinstance(mapping, dict):\n",
    "            self.mapping = mapping\n",
    "            self.value = None\n",
    "        else:\n",
    "            self.value = mapping\n",
    "            self.mapping = None\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        res = X.copy()\n",
    "        if self.mapping is not None:\n",
    "            for col, val in self.mapping.items():\n",
    "                res[col].fillna(val, inplace=True)\n",
    "        if self.value is not None:\n",
    "            res.fillna(self.value, inplace=True)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def pipeline_maker(pipeline, *args,  **kwargs):\n",
    "    def instantiate():\n",
    "        return pipeline(*args, **kwargs)\n",
    "    return instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially we choose features describing the event in general (e.g. photon number, lepton number, missing energy), then, since two photons are important features of the event we pick two the most energetic photons and include all the features describing them in detail (e.g. eta, phi, pt, E). Then we include aggregated features for leptons, like sum of phi, sum of energies, sum of theta. Finally, we include `h_mass`.\n",
    "\n",
    "Sometimes there are no leptons in the event, then we impose zero values for all the features describing them.\n",
    "\n",
    "Find the full feature list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photon_n</th>\n",
       "      <th>photon_1lead_pt</th>\n",
       "      <th>photon_1lead_eta</th>\n",
       "      <th>photon_1lead_phi</th>\n",
       "      <th>photon_1lead_E</th>\n",
       "      <th>photon_1lead_etcone20</th>\n",
       "      <th>photon_2lead_pt</th>\n",
       "      <th>photon_2lead_eta</th>\n",
       "      <th>photon_2lead_phi</th>\n",
       "      <th>photon_2lead_E</th>\n",
       "      <th>...</th>\n",
       "      <th>met_phi</th>\n",
       "      <th>lep_pt_sum</th>\n",
       "      <th>lep_phi_sum</th>\n",
       "      <th>lep_E_sum</th>\n",
       "      <th>lep_theta_sum</th>\n",
       "      <th>lep_charge_sum</th>\n",
       "      <th>lep_ptcone30_sum</th>\n",
       "      <th>lep_etcone20_sum</th>\n",
       "      <th>label</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34762</th>\n",
       "      <td>2</td>\n",
       "      <td>61186.055</td>\n",
       "      <td>0.745909</td>\n",
       "      <td>1.857736</td>\n",
       "      <td>79011.390</td>\n",
       "      <td>-214.42026</td>\n",
       "      <td>58043.250</td>\n",
       "      <td>-0.610472</td>\n",
       "      <td>-2.745476</td>\n",
       "      <td>69199.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tt</td>\n",
       "      <td>3.535056e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17522</th>\n",
       "      <td>2</td>\n",
       "      <td>57509.270</td>\n",
       "      <td>-0.547249</td>\n",
       "      <td>-3.109003</td>\n",
       "      <td>66337.810</td>\n",
       "      <td>-519.36290</td>\n",
       "      <td>49587.080</td>\n",
       "      <td>0.501637</td>\n",
       "      <td>-0.035371</td>\n",
       "      <td>55958.066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gg</td>\n",
       "      <td>6.375784e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47589</th>\n",
       "      <td>2</td>\n",
       "      <td>57872.516</td>\n",
       "      <td>-0.576206</td>\n",
       "      <td>-0.812393</td>\n",
       "      <td>67748.520</td>\n",
       "      <td>-733.14470</td>\n",
       "      <td>46447.676</td>\n",
       "      <td>0.728025</td>\n",
       "      <td>2.388419</td>\n",
       "      <td>59310.140</td>\n",
       "      <td>...</td>\n",
       "      <td>2.524073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gg</td>\n",
       "      <td>6.258318e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>2</td>\n",
       "      <td>156658.190</td>\n",
       "      <td>0.683966</td>\n",
       "      <td>-2.048359</td>\n",
       "      <td>194752.220</td>\n",
       "      <td>-242.73482</td>\n",
       "      <td>37639.945</td>\n",
       "      <td>0.693092</td>\n",
       "      <td>2.438658</td>\n",
       "      <td>47048.370</td>\n",
       "      <td>...</td>\n",
       "      <td>1.855891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>4.440460e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44652</th>\n",
       "      <td>2</td>\n",
       "      <td>84145.766</td>\n",
       "      <td>0.430823</td>\n",
       "      <td>-1.531170</td>\n",
       "      <td>92076.400</td>\n",
       "      <td>-1019.32764</td>\n",
       "      <td>27554.098</td>\n",
       "      <td>-1.093629</td>\n",
       "      <td>1.668323</td>\n",
       "      <td>45740.984</td>\n",
       "      <td>...</td>\n",
       "      <td>1.554219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gg</td>\n",
       "      <td>6.191731e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27005</th>\n",
       "      <td>2</td>\n",
       "      <td>66853.030</td>\n",
       "      <td>1.625911</td>\n",
       "      <td>0.868543</td>\n",
       "      <td>176484.560</td>\n",
       "      <td>-913.14026</td>\n",
       "      <td>42325.800</td>\n",
       "      <td>0.195025</td>\n",
       "      <td>-1.363790</td>\n",
       "      <td>43133.280</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.225946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VBF</td>\n",
       "      <td>1.540992e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>2</td>\n",
       "      <td>63004.390</td>\n",
       "      <td>0.887710</td>\n",
       "      <td>-0.333082</td>\n",
       "      <td>89502.695</td>\n",
       "      <td>-1976.89830</td>\n",
       "      <td>57729.113</td>\n",
       "      <td>-0.742256</td>\n",
       "      <td>-1.374505</td>\n",
       "      <td>74375.516</td>\n",
       "      <td>...</td>\n",
       "      <td>2.781973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VBF</td>\n",
       "      <td>5.338199e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19695</th>\n",
       "      <td>2</td>\n",
       "      <td>81314.836</td>\n",
       "      <td>1.139199</td>\n",
       "      <td>-2.058962</td>\n",
       "      <td>140037.980</td>\n",
       "      <td>-794.09393</td>\n",
       "      <td>65658.380</td>\n",
       "      <td>0.297407</td>\n",
       "      <td>-0.524126</td>\n",
       "      <td>68583.625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VBF</td>\n",
       "      <td>1.139801e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40489</th>\n",
       "      <td>2</td>\n",
       "      <td>73674.766</td>\n",
       "      <td>0.438450</td>\n",
       "      <td>-2.611038</td>\n",
       "      <td>80870.510</td>\n",
       "      <td>-242.98242</td>\n",
       "      <td>53581.746</td>\n",
       "      <td>-0.156901</td>\n",
       "      <td>1.061709</td>\n",
       "      <td>54242.637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gg</td>\n",
       "      <td>9.122884e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>2</td>\n",
       "      <td>75851.930</td>\n",
       "      <td>0.718618</td>\n",
       "      <td>-2.071324</td>\n",
       "      <td>96294.810</td>\n",
       "      <td>-349.21970</td>\n",
       "      <td>39224.625</td>\n",
       "      <td>-1.011326</td>\n",
       "      <td>2.746928</td>\n",
       "      <td>61052.750</td>\n",
       "      <td>...</td>\n",
       "      <td>1.460566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tt</td>\n",
       "      <td>5.701518e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38282 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       photon_n  photon_1lead_pt  photon_1lead_eta  photon_1lead_phi  \\\n",
       "34762         2        61186.055          0.745909          1.857736   \n",
       "17522         2        57509.270         -0.547249         -3.109003   \n",
       "47589         2        57872.516         -0.576206         -0.812393   \n",
       "1178          2       156658.190          0.683966         -2.048359   \n",
       "44652         2        84145.766          0.430823         -1.531170   \n",
       "...         ...              ...               ...               ...   \n",
       "27005         2        66853.030          1.625911          0.868543   \n",
       "3731          2        63004.390          0.887710         -0.333082   \n",
       "19695         2        81314.836          1.139199         -2.058962   \n",
       "40489         2        73674.766          0.438450         -2.611038   \n",
       "5236          2        75851.930          0.718618         -2.071324   \n",
       "\n",
       "       photon_1lead_E  photon_1lead_etcone20  photon_2lead_pt  \\\n",
       "34762       79011.390             -214.42026        58043.250   \n",
       "17522       66337.810             -519.36290        49587.080   \n",
       "47589       67748.520             -733.14470        46447.676   \n",
       "1178       194752.220             -242.73482        37639.945   \n",
       "44652       92076.400            -1019.32764        27554.098   \n",
       "...               ...                    ...              ...   \n",
       "27005      176484.560             -913.14026        42325.800   \n",
       "3731        89502.695            -1976.89830        57729.113   \n",
       "19695      140037.980             -794.09393        65658.380   \n",
       "40489       80870.510             -242.98242        53581.746   \n",
       "5236        96294.810             -349.21970        39224.625   \n",
       "\n",
       "       photon_2lead_eta  photon_2lead_phi  photon_2lead_E  ...   met_phi  \\\n",
       "34762         -0.610472         -2.745476       69199.020  ...  0.220448   \n",
       "17522          0.501637         -0.035371       55958.066  ... -0.051363   \n",
       "47589          0.728025          2.388419       59310.140  ...  2.524073   \n",
       "1178           0.693092          2.438658       47048.370  ...  1.855891   \n",
       "44652         -1.093629          1.668323       45740.984  ...  1.554219   \n",
       "...                 ...               ...             ...  ...       ...   \n",
       "27005          0.195025         -1.363790       43133.280  ... -1.225946   \n",
       "3731          -0.742256         -1.374505       74375.516  ...  2.781973   \n",
       "19695          0.297407         -0.524126       68583.625  ...  1.200092   \n",
       "40489         -0.156901          1.061709       54242.637  ... -0.364433   \n",
       "5236          -1.011326          2.746928       61052.750  ...  1.460566   \n",
       "\n",
       "       lep_pt_sum  lep_phi_sum  lep_E_sum  lep_theta_sum  lep_charge_sum  \\\n",
       "34762         0.0          0.0        0.0            0.0               0   \n",
       "17522         0.0          0.0        0.0            0.0               0   \n",
       "47589         0.0          0.0        0.0            0.0               0   \n",
       "1178          0.0          0.0        0.0            0.0               0   \n",
       "44652         0.0          0.0        0.0            0.0               0   \n",
       "...           ...          ...        ...            ...             ...   \n",
       "27005         0.0          0.0        0.0            0.0               0   \n",
       "3731          0.0          0.0        0.0            0.0               0   \n",
       "19695         0.0          0.0        0.0            0.0               0   \n",
       "40489         0.0          0.0        0.0            0.0               0   \n",
       "5236          0.0          0.0        0.0            0.0               0   \n",
       "\n",
       "       lep_ptcone30_sum  lep_etcone20_sum  label        weight  \n",
       "34762               0.0               0.0     tt  3.535056e-12  \n",
       "17522               0.0               0.0     gg  6.375784e-08  \n",
       "47589               0.0               0.0     gg  6.258318e-08  \n",
       "1178                0.0               0.0      Z  4.440460e-09  \n",
       "44652               0.0               0.0     gg  6.191731e-08  \n",
       "...                 ...               ...    ...           ...  \n",
       "27005               0.0               0.0    VBF  1.540992e-08  \n",
       "3731                0.0               0.0    VBF  5.338199e-09  \n",
       "19695               0.0               0.0    VBF  1.139801e-08  \n",
       "40489               0.0               0.0     gg  9.122884e-08  \n",
       "5236                0.0               0.0     tt  5.701518e-12  \n",
       "\n",
       "[38282 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BaselineFeaturePipeline = \\\n",
    "    pipeline_maker(Pipeline, steps=[\n",
    "        ('keep_features', KeepFeatures(['photon_n', 'photon_1lead_pt',\n",
    "                                        'photon_1lead_eta', 'photon_1lead_phi',\n",
    "                                        'photon_1lead_E', 'photon_1lead_etcone20',\n",
    "                                        'photon_2lead_pt', 'photon_2lead_eta',\n",
    "                                        'photon_2lead_phi', 'photon_2lead_E',\n",
    "                                        'photon_2lead_etcone20', 'h_mass',\n",
    "                                        'met_et', 'met_phi', 'lep_pt_sum',\n",
    "                                        'lep_phi_sum', 'lep_E_sum', 'lep_theta_sum',\n",
    "                                        'lep_charge_sum', 'lep_ptcone30_sum',\n",
    "                                        'lep_etcone20_sum', 'label', 'weight'])),\n",
    "        ('filna', FillNa(0.))\n",
    "    ])\n",
    "baseline_feature_pipeline = BaselineFeaturePipeline().fit(d_train)\n",
    "baseline_features = baseline_feature_pipeline.transform(d_train)\n",
    "baseline_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def split_targets(data, targets, drop=None):\n",
    "    flat_target = False\n",
    "    if not isinstance(targets, list):\n",
    "        flat_target = True\n",
    "    to_drop = drop if drop is not None else []\n",
    "    to_drop += targets if not flat_target else [targets]\n",
    "    \n",
    "    Xs = data.drop(columns=to_drop)\n",
    "    ys = data[targets]\n",
    "    \n",
    "    return Xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline model we pick RandomForestClassifier. RandomForest is useful to pick relevant features when the dataset possibly includes correlated features. Correlations are weakend because RandomForest picks a subset of features to train each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = RandomForestClassifier(random_state=RANDOM_STATE).fit(*split_targets(baseline_features, \"label\", drop=[\"weight\"]), sample_weight=baseline_features[\"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def extract_importances(feature_importances, feature_names):\n",
    "    return pd.DataFrame(zip(feature_names, feature_importances),\n",
    "                                      columns=[\"feature\", \"score\"]) \\\n",
    "             .set_index(\"feature\") \\\n",
    "             .sort_values(\"score\", axis=\"index\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def get_ensemble_feature_importances(ensemble_model):\n",
    "    importances = []\n",
    "    for est in ensemble_model.estimators_:\n",
    "        importances.append(est.steps[-1][1].feature_importances_)\n",
    "    importances = np.vstack(importances)\n",
    "    return np.median(importances, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def report_importances(model, X_test):\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        feature_importances = model.feature_importances_\n",
    "    elif hasattr(model, \"estimators_\") and hasattr(model.estimators_[0].steps[-1][1], \"feature_importances_\"):\n",
    "        feature_importances = get_ensemble_feature_importances(model)\n",
    "    else:\n",
    "        print(\"Model doesn't seem to provide feature importances. Skip feature importances report\")\n",
    "        return\n",
    "    nice_importances = extract_importances(feature_importances, X_test.columns)\n",
    "    print(\"Feature importances\")\n",
    "    display(nice_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def report_class_summary(model, feature_pipeline, X_test, y_test, weights=None):\n",
    "    if not hasattr(model, \"classes_\"):\n",
    "        print(\"Model doesn't seem to be a classificator. Skip classification summary report\")\n",
    "        return\n",
    "    classes = model.classes_\n",
    "    labeler = feature_pipeline.named_steps.get(\"labels\")\n",
    "    if labeler is not None:\n",
    "        classes = labeler.transformer.inverse_transform(classes)\n",
    "    print(\"Model classes\")\n",
    "    display(classes)\n",
    "    pred = model.predict(X_test)\n",
    "    conf = confusion_matrix(y_test, pred)\n",
    "    print(\"Confusion matrix, normalized\")\n",
    "    display(conf)\n",
    "    conf = confusion_matrix(y_test, pred, sample_weight=weights)\n",
    "    print(\"-Log confusion matrix of weights\")\n",
    "    display(-np.log(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def report_descriptive(X_test, y_test, weights=None):\n",
    "    data = pd.concat([X_test, y_test], axis=\"columns\")\n",
    "    if weights is not None:\n",
    "        data = data.assign(weight=weights)\n",
    "        \n",
    "    if \"weight\" in X_test.columns:\n",
    "        weight_sums = data.groupby(\"label\")[\"weight\"].sum()\n",
    "        print(\"Sum of weights\")\n",
    "        display(weight_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def report(model, feature_pipeline, d_test, drop=None):\n",
    "    X_test, y_test = split_targets(d_test, \"label\", drop=drop)\n",
    "    weights = d_test[\"weight\"]\n",
    "    report_descriptive(X_test, y_test, weights=weights)\n",
    "    report_class_summary(model, feature_pipeline, X_test, y_test, weights=weights)\n",
    "    report_importances(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model has been trained, let's see the report describing the baseline.\n",
    "\n",
    "We have 5 classes and a confusion matrix for them.\n",
    "\n",
    "We also provide confusion matrix for weights in somewhat sophisticated format. Due to weights can differ by orders of magnitude, it is easier to compare logarithms. Since all weights are < 1, it is convenient to remove minus sign close to numbers in the matrix. As a result, the smaller number on the diagonal of the matrix the better.\n",
    "\n",
    "Finally we show feature importances coming from decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['VBF', 'Wp', 'Z', 'gg', 'tt'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, normalized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 742,    1,    8, 1332,   18],\n",
       "       [ 109,   30,    5,  216,   78],\n",
       "       [ 252,    5,   52,  552,   75],\n",
       "       [ 690,    1,   16, 4423,   24],\n",
       "       [ 434,   69,   79,  693,  731]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Log confusion matrix of weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11.90195127, 18.28623683, 16.56816105, 11.29962974, 15.78736472],\n",
       "       [13.89770251, 15.29416078, 17.11034004, 13.28827271, 14.32358929],\n",
       "       [13.85717745, 17.7811933 , 15.58060626, 13.08836405, 15.18185408],\n",
       "       [10.24692536, 16.61507853, 13.93604945,  8.37420224, 13.81467997],\n",
       "       [20.33738557, 22.50416353, 22.07475397, 20.14704379, 19.95147436]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>photon_1lead_pt</th>\n",
       "      <td>0.092537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met_et</th>\n",
       "      <td>0.078401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_E</th>\n",
       "      <td>0.077665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_etcone20</th>\n",
       "      <td>0.077124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_pt</th>\n",
       "      <td>0.073294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_eta</th>\n",
       "      <td>0.072564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_E</th>\n",
       "      <td>0.071625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_eta</th>\n",
       "      <td>0.070407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_phi</th>\n",
       "      <td>0.070123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_phi</th>\n",
       "      <td>0.069216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_mass</th>\n",
       "      <td>0.068769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met_phi</th>\n",
       "      <td>0.068643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_etcone20</th>\n",
       "      <td>0.068406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_E_sum</th>\n",
       "      <td>0.015720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_pt_sum</th>\n",
       "      <td>0.009125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_charge_sum</th>\n",
       "      <td>0.005350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_theta_sum</th>\n",
       "      <td>0.002958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_etcone20_sum</th>\n",
       "      <td>0.002647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_phi_sum</th>\n",
       "      <td>0.002414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_n</th>\n",
       "      <td>0.002213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_ptcone30_sum</th>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          score\n",
       "feature                        \n",
       "photon_1lead_pt        0.092537\n",
       "met_et                 0.078401\n",
       "photon_1lead_E         0.077665\n",
       "photon_2lead_etcone20  0.077124\n",
       "photon_2lead_pt        0.073294\n",
       "photon_2lead_eta       0.072564\n",
       "photon_2lead_E         0.071625\n",
       "photon_1lead_eta       0.070407\n",
       "photon_2lead_phi       0.070123\n",
       "photon_1lead_phi       0.069216\n",
       "h_mass                 0.068769\n",
       "met_phi                0.068643\n",
       "photon_1lead_etcone20  0.068406\n",
       "lep_E_sum              0.015720\n",
       "lep_pt_sum             0.009125\n",
       "lep_charge_sum         0.005350\n",
       "lep_theta_sum          0.002958\n",
       "lep_etcone20_sum       0.002647\n",
       "lep_phi_sum            0.002414\n",
       "photon_n               0.002213\n",
       "lep_ptcone30_sum       0.000800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report(baseline_model, baseline_feature_pipeline, baseline_feature_pipeline.transform(d_test), drop=[\"weight\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently `gg` events are so many, that other events become classified as `gg` just statistically. This means that the dataset is imbalanced, and we should find some approach to target this issue.\n",
    "\n",
    "We also choose subset of features to work with. We pick only significantly relevant features. See the list of them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def mask_by_levels(data, threshold=None, limit=None):\n",
    "    thr_mask = np.array(True)\n",
    "    if threshold is not None:\n",
    "        if isinstance(threshold, dict):\n",
    "            thr_mask = np.all([data[k] > v for k,v in threshold.items()])\n",
    "        else:\n",
    "            thr_mask = np.all(data > threshold, axis=1)\n",
    "    \n",
    "    lim_mask = np.array(True)\n",
    "    if limit is not None:\n",
    "        if isinstance(limit, dict):\n",
    "            lim_mask = np.all([data[k] < v for k,v in limit.items()])\n",
    "        else:\n",
    "            lim_mask = np.all(data < limit, axis=1)\n",
    "            \n",
    "    mask = thr_mask & lim_mask\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def filter_by_levels(data, threshold=None, limit=None):\n",
    "    mask = mask_by_levels(data, threshold=threshold, limit=limit)\n",
    "    \n",
    "    if np.all(mask):\n",
    "        return data.copy()\n",
    "    else:\n",
    "        return data[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['photon_1lead_pt',\n",
       " 'met_et',\n",
       " 'photon_1lead_E',\n",
       " 'photon_2lead_etcone20',\n",
       " 'photon_2lead_pt',\n",
       " 'photon_2lead_eta',\n",
       " 'photon_2lead_E',\n",
       " 'photon_1lead_eta',\n",
       " 'photon_2lead_phi',\n",
       " 'photon_1lead_phi',\n",
       " 'h_mass',\n",
       " 'met_phi',\n",
       " 'photon_1lead_etcone20']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcolumns = list(filter_by_levels(\n",
    "                extract_importances(\n",
    "                    baseline_model.feature_importances_,\n",
    "                    split_targets(baseline_features, \"label\", drop=[\"weight\"])[0].columns\n",
    "                ),\n",
    "                threshold=0.05\n",
    "             ).index)\n",
    "subcolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "class WithColumns(TransformerMixin):\n",
    "    def __init__(self, transformer, columns=None):\n",
    "        self.columns = columns\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.transformer.fit(X[self.columns])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        res = X.copy()\n",
    "        res[self.columns] = self.transformer.transform(res[self.columns])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "class ReplaceValues(TransformerMixin):\n",
    "    def __init__(self, mapping):\n",
    "        self.mapping = mapping\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        res = X.replace(self.mapping)\n",
    "        return res\n",
    "# WithColumns(ReplaceValues({\n",
    "#                                 \"VBF\": \"other\",\n",
    "#                                 \"Wp\": \"other\",\n",
    "#                                 \"Z\": \"other\",\n",
    "#                                 \"gg\": \"other\"\n",
    "#                                }), columns=\"label\").fit_transform(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "class DropByLevel(TransformerMixin):\n",
    "    def __init__(self, column, threshold=None, limit=None):\n",
    "        self.column = column\n",
    "        self.threshold = threshold\n",
    "        self.limit = limit\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        mask = mask_by_levels(X[self.column], threshold=self.threshold, limit=self.limit)\n",
    "        \n",
    "        if np.all(mask):\n",
    "            return X.copy()\n",
    "        \n",
    "        return X[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "class DropByValues(TransformerMixin):\n",
    "    def __init__(self, column, values):\n",
    "        self.column = column\n",
    "        self.values = values\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        mask = ~np.any([X[self.column] == v for v in self.values], axis=0)\n",
    "        \n",
    "        if np.all(mask):\n",
    "            return X.copy()\n",
    "        \n",
    "        return X[mask].copy()\n",
    "# DropByValues(\"label\", [\"tt\"]).fit_transform(d_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature processing for next to baseline model, we name it `significant imbalanced model` is a bit more complex. As before, we fill empty values for chosen features with zeros.\n",
    "\n",
    "We also drop `tt`, `Wp` and `Z` events for this step. We try to focus on events that have similar weight per event. `Wp` and `Z` are few but they are very heavy, while `tt` are quite a lot but weight is tiny. It is quite hard to handle such a mixture together.\n",
    "\n",
    "Now we end up with `gg` and `VBF` events. The dataset is still imbalanced from the number of events perspective, but at the same time we can bother less about their weights.\n",
    "\n",
    "As a part of feature processing, we also drop negative weights. That's just a technical issue, because the algorithm we are going to apply can't handle negative weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photon_1lead_pt</th>\n",
       "      <th>met_et</th>\n",
       "      <th>photon_1lead_E</th>\n",
       "      <th>photon_2lead_etcone20</th>\n",
       "      <th>photon_2lead_pt</th>\n",
       "      <th>photon_2lead_eta</th>\n",
       "      <th>photon_2lead_E</th>\n",
       "      <th>photon_1lead_eta</th>\n",
       "      <th>photon_2lead_phi</th>\n",
       "      <th>photon_1lead_phi</th>\n",
       "      <th>h_mass</th>\n",
       "      <th>met_phi</th>\n",
       "      <th>photon_1lead_etcone20</th>\n",
       "      <th>label</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17522</th>\n",
       "      <td>57509.270</td>\n",
       "      <td>24200.309</td>\n",
       "      <td>66337.810</td>\n",
       "      <td>-94.554214</td>\n",
       "      <td>49587.080</td>\n",
       "      <td>0.501637</td>\n",
       "      <td>55958.066</td>\n",
       "      <td>-0.547249</td>\n",
       "      <td>-0.035371</td>\n",
       "      <td>-3.109003</td>\n",
       "      <td>119516.130</td>\n",
       "      <td>-0.051363</td>\n",
       "      <td>-519.36290</td>\n",
       "      <td>1</td>\n",
       "      <td>6.375784e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47589</th>\n",
       "      <td>57872.516</td>\n",
       "      <td>40232.438</td>\n",
       "      <td>67748.520</td>\n",
       "      <td>-1234.568200</td>\n",
       "      <td>46447.676</td>\n",
       "      <td>0.728025</td>\n",
       "      <td>59310.140</td>\n",
       "      <td>-0.576206</td>\n",
       "      <td>2.388419</td>\n",
       "      <td>-0.812393</td>\n",
       "      <td>119186.875</td>\n",
       "      <td>2.524073</td>\n",
       "      <td>-733.14470</td>\n",
       "      <td>1</td>\n",
       "      <td>6.258318e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44652</th>\n",
       "      <td>84145.766</td>\n",
       "      <td>51859.027</td>\n",
       "      <td>92076.400</td>\n",
       "      <td>-86.023605</td>\n",
       "      <td>27554.098</td>\n",
       "      <td>-1.093629</td>\n",
       "      <td>45740.984</td>\n",
       "      <td>0.430823</td>\n",
       "      <td>1.668323</td>\n",
       "      <td>-1.531170</td>\n",
       "      <td>129246.170</td>\n",
       "      <td>1.554219</td>\n",
       "      <td>-1019.32764</td>\n",
       "      <td>1</td>\n",
       "      <td>6.191731e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29709</th>\n",
       "      <td>73832.836</td>\n",
       "      <td>54375.840</td>\n",
       "      <td>81773.960</td>\n",
       "      <td>-1200.018900</td>\n",
       "      <td>41363.820</td>\n",
       "      <td>-0.561445</td>\n",
       "      <td>48056.250</td>\n",
       "      <td>0.459741</td>\n",
       "      <td>0.420344</td>\n",
       "      <td>-2.871648</td>\n",
       "      <td>123697.970</td>\n",
       "      <td>0.346971</td>\n",
       "      <td>-786.47240</td>\n",
       "      <td>1</td>\n",
       "      <td>4.847792e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43025</th>\n",
       "      <td>63447.668</td>\n",
       "      <td>45032.043</td>\n",
       "      <td>108673.080</td>\n",
       "      <td>-328.382870</td>\n",
       "      <td>51555.555</td>\n",
       "      <td>-0.104425</td>\n",
       "      <td>51836.906</td>\n",
       "      <td>1.132488</td>\n",
       "      <td>1.424528</td>\n",
       "      <td>-0.659084</td>\n",
       "      <td>119599.125</td>\n",
       "      <td>2.748239</td>\n",
       "      <td>-1129.62730</td>\n",
       "      <td>1</td>\n",
       "      <td>3.888226e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35735</th>\n",
       "      <td>48830.830</td>\n",
       "      <td>10524.696</td>\n",
       "      <td>61091.420</td>\n",
       "      <td>-323.829160</td>\n",
       "      <td>48478.434</td>\n",
       "      <td>-0.914525</td>\n",
       "      <td>70203.940</td>\n",
       "      <td>0.694590</td>\n",
       "      <td>-1.118841</td>\n",
       "      <td>2.793305</td>\n",
       "      <td>122219.350</td>\n",
       "      <td>-0.686762</td>\n",
       "      <td>-579.96560</td>\n",
       "      <td>1</td>\n",
       "      <td>6.394328e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27005</th>\n",
       "      <td>66853.030</td>\n",
       "      <td>71642.560</td>\n",
       "      <td>176484.560</td>\n",
       "      <td>-1256.716200</td>\n",
       "      <td>42325.800</td>\n",
       "      <td>0.195025</td>\n",
       "      <td>43133.280</td>\n",
       "      <td>1.625911</td>\n",
       "      <td>-1.363790</td>\n",
       "      <td>0.868543</td>\n",
       "      <td>127275.800</td>\n",
       "      <td>-1.225946</td>\n",
       "      <td>-913.14026</td>\n",
       "      <td>0</td>\n",
       "      <td>1.540992e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>63004.390</td>\n",
       "      <td>78592.805</td>\n",
       "      <td>89502.695</td>\n",
       "      <td>-372.513120</td>\n",
       "      <td>57729.113</td>\n",
       "      <td>-0.742256</td>\n",
       "      <td>74375.516</td>\n",
       "      <td>0.887710</td>\n",
       "      <td>-1.374505</td>\n",
       "      <td>-0.333082</td>\n",
       "      <td>125533.550</td>\n",
       "      <td>2.781973</td>\n",
       "      <td>-1976.89830</td>\n",
       "      <td>0</td>\n",
       "      <td>5.338199e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19695</th>\n",
       "      <td>81314.836</td>\n",
       "      <td>59611.215</td>\n",
       "      <td>140037.980</td>\n",
       "      <td>-868.619570</td>\n",
       "      <td>65658.380</td>\n",
       "      <td>0.297407</td>\n",
       "      <td>68583.625</td>\n",
       "      <td>1.139199</td>\n",
       "      <td>-0.524126</td>\n",
       "      <td>-2.058962</td>\n",
       "      <td>122452.530</td>\n",
       "      <td>1.200092</td>\n",
       "      <td>-794.09393</td>\n",
       "      <td>0</td>\n",
       "      <td>1.139801e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40489</th>\n",
       "      <td>73674.766</td>\n",
       "      <td>27399.121</td>\n",
       "      <td>80870.510</td>\n",
       "      <td>-646.382900</td>\n",
       "      <td>53581.746</td>\n",
       "      <td>-0.156901</td>\n",
       "      <td>54242.637</td>\n",
       "      <td>0.438450</td>\n",
       "      <td>1.061709</td>\n",
       "      <td>-2.611038</td>\n",
       "      <td>128337.260</td>\n",
       "      <td>-0.364433</td>\n",
       "      <td>-242.98242</td>\n",
       "      <td>1</td>\n",
       "      <td>9.122884e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25855 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       photon_1lead_pt     met_et  photon_1lead_E  photon_2lead_etcone20  \\\n",
       "17522        57509.270  24200.309       66337.810             -94.554214   \n",
       "47589        57872.516  40232.438       67748.520           -1234.568200   \n",
       "44652        84145.766  51859.027       92076.400             -86.023605   \n",
       "29709        73832.836  54375.840       81773.960           -1200.018900   \n",
       "43025        63447.668  45032.043      108673.080            -328.382870   \n",
       "...                ...        ...             ...                    ...   \n",
       "35735        48830.830  10524.696       61091.420            -323.829160   \n",
       "27005        66853.030  71642.560      176484.560           -1256.716200   \n",
       "3731         63004.390  78592.805       89502.695            -372.513120   \n",
       "19695        81314.836  59611.215      140037.980            -868.619570   \n",
       "40489        73674.766  27399.121       80870.510            -646.382900   \n",
       "\n",
       "       photon_2lead_pt  photon_2lead_eta  photon_2lead_E  photon_1lead_eta  \\\n",
       "17522        49587.080          0.501637       55958.066         -0.547249   \n",
       "47589        46447.676          0.728025       59310.140         -0.576206   \n",
       "44652        27554.098         -1.093629       45740.984          0.430823   \n",
       "29709        41363.820         -0.561445       48056.250          0.459741   \n",
       "43025        51555.555         -0.104425       51836.906          1.132488   \n",
       "...                ...               ...             ...               ...   \n",
       "35735        48478.434         -0.914525       70203.940          0.694590   \n",
       "27005        42325.800          0.195025       43133.280          1.625911   \n",
       "3731         57729.113         -0.742256       74375.516          0.887710   \n",
       "19695        65658.380          0.297407       68583.625          1.139199   \n",
       "40489        53581.746         -0.156901       54242.637          0.438450   \n",
       "\n",
       "       photon_2lead_phi  photon_1lead_phi      h_mass   met_phi  \\\n",
       "17522         -0.035371         -3.109003  119516.130 -0.051363   \n",
       "47589          2.388419         -0.812393  119186.875  2.524073   \n",
       "44652          1.668323         -1.531170  129246.170  1.554219   \n",
       "29709          0.420344         -2.871648  123697.970  0.346971   \n",
       "43025          1.424528         -0.659084  119599.125  2.748239   \n",
       "...                 ...               ...         ...       ...   \n",
       "35735         -1.118841          2.793305  122219.350 -0.686762   \n",
       "27005         -1.363790          0.868543  127275.800 -1.225946   \n",
       "3731          -1.374505         -0.333082  125533.550  2.781973   \n",
       "19695         -0.524126         -2.058962  122452.530  1.200092   \n",
       "40489          1.061709         -2.611038  128337.260 -0.364433   \n",
       "\n",
       "       photon_1lead_etcone20  label        weight  \n",
       "17522             -519.36290      1  6.375784e-08  \n",
       "47589             -733.14470      1  6.258318e-08  \n",
       "44652            -1019.32764      1  6.191731e-08  \n",
       "29709             -786.47240      1  4.847792e-08  \n",
       "43025            -1129.62730      1  3.888226e-08  \n",
       "...                      ...    ...           ...  \n",
       "35735             -579.96560      1  6.394328e-08  \n",
       "27005             -913.14026      0  1.540992e-08  \n",
       "3731             -1976.89830      0  5.338199e-09  \n",
       "19695             -794.09393      0  1.139801e-08  \n",
       "40489             -242.98242      1  9.122884e-08  \n",
       "\n",
       "[25855 rows x 15 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SignificantFeaturePipeline = \\\n",
    "    pipeline_maker(Pipeline, steps=[\n",
    "        ('keep_features', KeepFeatures(subcolumns + [\"label\", \"weight\"])),\n",
    "        ('filna', FillNa(0.)),\n",
    "        ('drop_tt', DropByValues(\"label\", [\"tt\", \"Wp\", \"Z\"])),\n",
    "        ('drop_neg_weight', DropByLevel([\"weight\"], threshold=0)),\n",
    "        ('labels', WithColumns(LabelEncoder(), columns=\"label\"))\n",
    "    ])\n",
    "significant_feature_pipeline = SignificantFeaturePipeline().fit(d_train)\n",
    "significant_features = significant_feature_pipeline.transform(d_train)\n",
    "significant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(significant_features[\"weight\"] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the reference about usage of [bagging for imbalanced datasets](https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/) we focus on the model of Easy Ensemble. It is an ensemble model, where AdaBoost (a variant of BDT) is used as a base estimator. The goal is to downsample major class in order to balance the trainig sample.\n",
    "\n",
    "To avoid throwing out the data we train 6 different AdaBoosts on different samples, where minority class is always entirely included, while events from majority class are downsampled to fit number of events in the minority class.\n",
    "\n",
    "After 6 different base estimators have been trained, the voting procedure decides on the prediction for the specific test event.\n",
    "\n",
    "\n",
    "\\* Note: we had to monkey-patch the AdaBoostClassifier to allow EasyEnsemble implementation to use sample weights. See details in the full version of the notebook in the github repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "class WeightedAdaBoost(AdaBoostClassifier):\n",
    "    def __init__(self,\n",
    "                 base_estimator=None, *,\n",
    "                 n_estimators=50,\n",
    "                 learning_rate=1.,\n",
    "                 algorithm='SAMME.R',\n",
    "                 random_state=None, weights_column=None):\n",
    "\n",
    "        super().__init__(\n",
    "            base_estimator=base_estimator,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            random_state=random_state)\n",
    "        self.weights_column = weights_column\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        super().fit(np.delete(X, self.weights_column, 1), y, sample_weight=X[:, self.weights_column])\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return super().predict(np.delete(X, self.weights_column, 1))\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return super().predict_proba(np.delete(X, self.weights_column, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_imbal_model = EasyEnsembleClassifier( \\\n",
    "                                          n_estimators=6,\n",
    "                                          base_estimator=WeightedAdaBoost(weights_column=list(split_targets(significant_features, \"label\")[0].columns).index(\"weight\")),\n",
    "                                          random_state=RANDOM_STATE,\n",
    "                                          sampling_strategy=\"not minority\",\n",
    "                                          replacement=False\n",
    "                                         ) \\\n",
    "                   .fit(*split_targets(significant_features, \"label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a report following the same structure as we had for the baseline model.\n",
    "\n",
    "Here we have 2 classes with a simple confusion matrix. It shows that we still didn't manage to fight the imbalance.\n",
    "\n",
    "Since here we have ensemble of BDTs, as feature importance we show median of scores per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.000019\n",
       "1    0.000268\n",
       "Name: weight, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['VBF', 'gg'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, normalized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  81, 1969],\n",
       "       [  57, 4985]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Log confusion matrix of weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[14.0949592 , 10.88880119],\n",
       "       [12.69525536,  8.23451207]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>photon_1lead_pt</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_eta</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_eta</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_pt</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_E</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met_et</th>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_E</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_etcone20</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_phi</th>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_mass</th>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met_phi</th>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_etcone20</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_phi</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       score\n",
       "feature                     \n",
       "photon_1lead_pt         0.22\n",
       "photon_2lead_eta        0.15\n",
       "photon_1lead_eta        0.12\n",
       "photon_2lead_pt         0.08\n",
       "photon_2lead_E          0.08\n",
       "met_et                  0.07\n",
       "photon_1lead_E          0.05\n",
       "photon_2lead_etcone20   0.05\n",
       "photon_2lead_phi        0.04\n",
       "h_mass                  0.04\n",
       "met_phi                 0.04\n",
       "photon_1lead_etcone20   0.02\n",
       "photon_1lead_phi        0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report(sign_imbal_model, significant_feature_pipeline, significant_feature_pipeline.transform(d_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
