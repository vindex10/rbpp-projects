{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.ensemble import EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/afs/cern.ch/user/a/ananiev/cernbox/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(data_path, \"hgg_features.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of entries per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_num</th>\n",
       "      <th>weight_sums</th>\n",
       "      <th>weight_frac</th>\n",
       "      <th>weight_per_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VBF</th>\n",
       "      <td>10369</td>\n",
       "      <td>9.612055e-05</td>\n",
       "      <td>0.064293</td>\n",
       "      <td>9.269992e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wp</th>\n",
       "      <td>2112</td>\n",
       "      <td>1.702021e-05</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>8.058813e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>4571</td>\n",
       "      <td>1.697019e-05</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>3.712578e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gg</th>\n",
       "      <td>26258</td>\n",
       "      <td>1.364896e-03</td>\n",
       "      <td>0.912952</td>\n",
       "      <td>5.198020e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt</th>\n",
       "      <td>9861</td>\n",
       "      <td>2.851057e-08</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>2.891245e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     event_num   weight_sums  weight_frac  weight_per_event\n",
       "VBF      10369  9.612055e-05     0.064293      9.269992e-09\n",
       "Wp        2112  1.702021e-05     0.011384      8.058813e-09\n",
       "Z         4571  1.697019e-05     0.011351      3.712578e-09\n",
       "gg       26258  1.364896e-03     0.912952      5.198020e-08\n",
       "tt        9861  2.851057e-08     0.000019      2.891245e-12"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weight_descriptive(data):\n",
    "    res = {}\n",
    "    \n",
    "    event_counts = data[\"label\"].value_counts().sort_values(ascending=False)\n",
    "    res[\"event_num\"] = event_counts\n",
    "    \n",
    "    weight_sums = data.groupby(\"label\")[\"weight\"].sum().sort_values(ascending=False)\n",
    "    res[\"weight_sums\"] = weight_sums\n",
    "    \n",
    "    weight_frac = weight_sums/data[\"weight\"].sum()\n",
    "    res[\"weight_frac\"] = weight_frac\n",
    "    \n",
    "    weight_per_event = weight_sums/event_counts\n",
    "    res[\"weight_per_event\"] = weight_per_event\n",
    "    \n",
    "    return pd.DataFrame(res)\n",
    "weight_descriptive(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "\n",
    "* **tt** events are not a lot, and they have relatively small weight\n",
    "* **Wp**, **Z** are quite few, but the weight is significant\n",
    "* **VBF** are quite a lot and the weight is mediocre\n",
    "* **gg** are the decent majority, while their weight is quite small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['photon_n', 'photon_1lead_pt', 'photon_1lead_eta', 'photon_1lead_phi',\n",
       "       'photon_1lead_E', 'photon_1lead_etcone20', 'photon_2lead_pt',\n",
       "       'photon_2lead_eta', 'photon_2lead_phi', 'photon_2lead_E',\n",
       "       'photon_2lead_etcone20', 'h_mass', 'lep_n', 'lep_pt_min', 'lep_pt_max',\n",
       "       'lep_pt_mean', 'lep_pt_sum', 'lep_pt_std', 'lep_phi_min', 'lep_phi_max',\n",
       "       'lep_phi_mean', 'lep_phi_sum', 'lep_phi_std', 'lep_E_min', 'lep_E_max',\n",
       "       'lep_E_mean', 'lep_E_sum', 'lep_E_std', 'lep_theta_min',\n",
       "       'lep_theta_max', 'lep_theta_mean', 'lep_theta_sum', 'lep_theta_std',\n",
       "       'lep_charge_min', 'lep_charge_max', 'lep_charge_mean', 'lep_charge_sum',\n",
       "       'lep_charge_std', 'lep_z0_min', 'lep_z0_max', 'lep_z0_mean',\n",
       "       'lep_z0_sum', 'lep_z0_std', 'lep_ptcone30_min', 'lep_ptcone30_max',\n",
       "       'lep_ptcone30_mean', 'lep_ptcone30_sum', 'lep_ptcone30_std',\n",
       "       'lep_etcone20_min', 'lep_etcone20_max', 'lep_etcone20_mean',\n",
       "       'lep_etcone20_sum', 'lep_etcone20_std', 'weight', 'met_et', 'met_phi',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train baseline model with ensemble of trees in order to identify at least somewhat relevant features to the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(dataset, target, test_size, val_size, *args, **kwargs):\n",
    "    shuffle = kwargs.get(\"shuffle\", True)\n",
    "    del kwargs[\"shuffle\"]\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(data.drop(columns=[target]), data[target], *args, test_size=test_size, shuffle=shuffle, **kwargs)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_size, shuffle=False, **kwargs)\n",
    "    return (pd.concat([X_train, y_train], axis=\"columns\"),\n",
    "            pd.concat([X_val, y_val], axis=\"columns\"),\n",
    "            pd.concat([X_test, y_test], axis=\"columns\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train, d_val, d_test = train_test_val_split(data, \"label\", 0.2, 0.1, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeepFeatures(TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X[self.features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FillNa(TransformerMixin):\n",
    "    def __init__(self, mapping):\n",
    "        if isinstance(mapping, dict):\n",
    "            self.mapping = mapping\n",
    "            self.value = None\n",
    "        else:\n",
    "            self.value = mapping\n",
    "            self.mapping = None\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        res = X.copy()\n",
    "        if self.mapping is not None:\n",
    "            for col, val in self.mapping.items():\n",
    "                res[col].fillna(val, inplace=True)\n",
    "        if self.value is not None:\n",
    "            res.fillna(self.value, inplace=True)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_maker(pipeline, *args,  **kwargs):\n",
    "    def instantiate():\n",
    "        return pipeline(*args, **kwargs)\n",
    "    return instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially we choose features describing the event in general (e.g. photon number, lepton number, missing energy), then, since two photons are important features of the event we pick two the most energetic photons and include all the features describing them in detail (e.g. eta, phi, pt, E). Then we include aggregated features for leptons, like sum of phi, sum of energies, sum of theta. Finally, we include `h_mass`.\n",
    "\n",
    "Sometimes there are no leptons in the event, then we impose zero values for all the features describing them.\n",
    "\n",
    "Find the full feature list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photon_n</th>\n",
       "      <th>photon_1lead_pt</th>\n",
       "      <th>photon_1lead_eta</th>\n",
       "      <th>photon_1lead_phi</th>\n",
       "      <th>photon_1lead_E</th>\n",
       "      <th>photon_1lead_etcone20</th>\n",
       "      <th>photon_2lead_pt</th>\n",
       "      <th>photon_2lead_eta</th>\n",
       "      <th>photon_2lead_phi</th>\n",
       "      <th>photon_2lead_E</th>\n",
       "      <th>...</th>\n",
       "      <th>met_phi</th>\n",
       "      <th>lep_pt_sum</th>\n",
       "      <th>lep_phi_sum</th>\n",
       "      <th>lep_E_sum</th>\n",
       "      <th>lep_theta_sum</th>\n",
       "      <th>lep_charge_sum</th>\n",
       "      <th>lep_ptcone30_sum</th>\n",
       "      <th>lep_etcone20_sum</th>\n",
       "      <th>label</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34762</th>\n",
       "      <td>2</td>\n",
       "      <td>68985.805</td>\n",
       "      <td>0.673179</td>\n",
       "      <td>-2.755656</td>\n",
       "      <td>85216.230</td>\n",
       "      <td>-33.086610</td>\n",
       "      <td>51873.760</td>\n",
       "      <td>-0.020217</td>\n",
       "      <td>0.261481</td>\n",
       "      <td>51884.363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.911852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gg</td>\n",
       "      <td>6.426950e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17522</th>\n",
       "      <td>2</td>\n",
       "      <td>65926.590</td>\n",
       "      <td>0.837155</td>\n",
       "      <td>-0.814143</td>\n",
       "      <td>90409.340</td>\n",
       "      <td>-849.875100</td>\n",
       "      <td>53449.170</td>\n",
       "      <td>-0.161098</td>\n",
       "      <td>1.488379</td>\n",
       "      <td>54144.246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773666</td>\n",
       "      <td>90692.882812</td>\n",
       "      <td>2.059564</td>\n",
       "      <td>98187.476562</td>\n",
       "      <td>-1.300542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1044.006714</td>\n",
       "      <td>4777.929199</td>\n",
       "      <td>tt</td>\n",
       "      <td>-6.256355e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47589</th>\n",
       "      <td>2</td>\n",
       "      <td>66244.650</td>\n",
       "      <td>0.284815</td>\n",
       "      <td>-0.899317</td>\n",
       "      <td>68949.734</td>\n",
       "      <td>-430.340760</td>\n",
       "      <td>49499.246</td>\n",
       "      <td>-0.664182</td>\n",
       "      <td>2.492585</td>\n",
       "      <td>60824.562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gg</td>\n",
       "      <td>6.509352e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>2</td>\n",
       "      <td>77618.510</td>\n",
       "      <td>1.311288</td>\n",
       "      <td>0.615234</td>\n",
       "      <td>154477.250</td>\n",
       "      <td>-1098.243200</td>\n",
       "      <td>40889.438</td>\n",
       "      <td>-0.005911</td>\n",
       "      <td>2.722577</td>\n",
       "      <td>40890.152</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.790231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Wp</td>\n",
       "      <td>9.925904e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44652</th>\n",
       "      <td>2</td>\n",
       "      <td>62168.310</td>\n",
       "      <td>-1.100176</td>\n",
       "      <td>-2.316379</td>\n",
       "      <td>103743.570</td>\n",
       "      <td>-257.241940</td>\n",
       "      <td>43533.900</td>\n",
       "      <td>0.573396</td>\n",
       "      <td>2.214298</td>\n",
       "      <td>50888.734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gg</td>\n",
       "      <td>6.574681e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27005</th>\n",
       "      <td>2</td>\n",
       "      <td>112069.280</td>\n",
       "      <td>-0.583809</td>\n",
       "      <td>-2.605017</td>\n",
       "      <td>131716.360</td>\n",
       "      <td>-653.104550</td>\n",
       "      <td>28948.701</td>\n",
       "      <td>0.584124</td>\n",
       "      <td>1.303498</td>\n",
       "      <td>34029.387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>tt</td>\n",
       "      <td>6.959701e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>2</td>\n",
       "      <td>54486.168</td>\n",
       "      <td>0.245120</td>\n",
       "      <td>-2.648435</td>\n",
       "      <td>56131.250</td>\n",
       "      <td>-50.511497</td>\n",
       "      <td>48930.305</td>\n",
       "      <td>-1.057293</td>\n",
       "      <td>0.539349</td>\n",
       "      <td>78923.680</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.251780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Z</td>\n",
       "      <td>4.961111e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19695</th>\n",
       "      <td>2</td>\n",
       "      <td>62460.710</td>\n",
       "      <td>0.404643</td>\n",
       "      <td>-2.093862</td>\n",
       "      <td>67644.390</td>\n",
       "      <td>-138.293850</td>\n",
       "      <td>48761.650</td>\n",
       "      <td>-0.666147</td>\n",
       "      <td>1.519702</td>\n",
       "      <td>59986.727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gg</td>\n",
       "      <td>3.565212e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40489</th>\n",
       "      <td>2</td>\n",
       "      <td>66830.560</td>\n",
       "      <td>0.162774</td>\n",
       "      <td>-1.102934</td>\n",
       "      <td>67717.870</td>\n",
       "      <td>-623.463500</td>\n",
       "      <td>45487.150</td>\n",
       "      <td>-0.942891</td>\n",
       "      <td>1.962060</td>\n",
       "      <td>67250.305</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.235665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gg</td>\n",
       "      <td>6.799428e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>2</td>\n",
       "      <td>89904.150</td>\n",
       "      <td>0.410700</td>\n",
       "      <td>2.252704</td>\n",
       "      <td>97593.580</td>\n",
       "      <td>-528.382600</td>\n",
       "      <td>75717.040</td>\n",
       "      <td>1.006672</td>\n",
       "      <td>-2.517539</td>\n",
       "      <td>117433.766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gg</td>\n",
       "      <td>6.514316e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38282 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       photon_n  photon_1lead_pt  photon_1lead_eta  photon_1lead_phi  \\\n",
       "34762         2        68985.805          0.673179         -2.755656   \n",
       "17522         2        65926.590          0.837155         -0.814143   \n",
       "47589         2        66244.650          0.284815         -0.899317   \n",
       "1178          2        77618.510          1.311288          0.615234   \n",
       "44652         2        62168.310         -1.100176         -2.316379   \n",
       "...         ...              ...               ...               ...   \n",
       "27005         2       112069.280         -0.583809         -2.605017   \n",
       "3731          2        54486.168          0.245120         -2.648435   \n",
       "19695         2        62460.710          0.404643         -2.093862   \n",
       "40489         2        66830.560          0.162774         -1.102934   \n",
       "5236          2        89904.150          0.410700          2.252704   \n",
       "\n",
       "       photon_1lead_E  photon_1lead_etcone20  photon_2lead_pt  \\\n",
       "34762       85216.230             -33.086610        51873.760   \n",
       "17522       90409.340            -849.875100        53449.170   \n",
       "47589       68949.734            -430.340760        49499.246   \n",
       "1178       154477.250           -1098.243200        40889.438   \n",
       "44652      103743.570            -257.241940        43533.900   \n",
       "...               ...                    ...              ...   \n",
       "27005      131716.360            -653.104550        28948.701   \n",
       "3731        56131.250             -50.511497        48930.305   \n",
       "19695       67644.390            -138.293850        48761.650   \n",
       "40489       67717.870            -623.463500        45487.150   \n",
       "5236        97593.580            -528.382600        75717.040   \n",
       "\n",
       "       photon_2lead_eta  photon_2lead_phi  photon_2lead_E  ...   met_phi  \\\n",
       "34762         -0.020217          0.261481       51884.363  ... -0.911852   \n",
       "17522         -0.161098          1.488379       54144.246  ...  0.773666   \n",
       "47589         -0.664182          2.492585       60824.562  ...  0.882567   \n",
       "1178          -0.005911          2.722577       40890.152  ... -2.790231   \n",
       "44652          0.573396          2.214298       50888.734  ... -0.120469   \n",
       "...                 ...               ...             ...  ...       ...   \n",
       "27005          0.584124          1.303498       34029.387  ...  0.420166   \n",
       "3731          -1.057293          0.539349       78923.680  ... -2.251780   \n",
       "19695         -0.666147          1.519702       59986.727  ...  0.057860   \n",
       "40489         -0.942891          1.962060       67250.305  ... -1.235665   \n",
       "5236           1.006672         -2.517539      117433.766  ...  0.124677   \n",
       "\n",
       "         lep_pt_sum  lep_phi_sum     lep_E_sum  lep_theta_sum  lep_charge_sum  \\\n",
       "34762      0.000000     0.000000      0.000000       0.000000             0.0   \n",
       "17522  90692.882812     2.059564  98187.476562      -1.300542             1.0   \n",
       "47589      0.000000     0.000000      0.000000       0.000000             0.0   \n",
       "1178       0.000000     0.000000      0.000000       0.000000             0.0   \n",
       "44652      0.000000     0.000000      0.000000       0.000000             0.0   \n",
       "...             ...          ...           ...            ...             ...   \n",
       "27005      0.000000     0.000000      0.000000       0.000000             0.0   \n",
       "3731       0.000000     0.000000      0.000000       0.000000             0.0   \n",
       "19695      0.000000     0.000000      0.000000       0.000000             0.0   \n",
       "40489      0.000000     0.000000      0.000000       0.000000             0.0   \n",
       "5236       0.000000     0.000000      0.000000       0.000000             0.0   \n",
       "\n",
       "       lep_ptcone30_sum  lep_etcone20_sum  label        weight  \n",
       "34762          0.000000          0.000000     gg  6.426950e-08  \n",
       "17522       1044.006714       4777.929199     tt -6.256355e-12  \n",
       "47589          0.000000          0.000000     gg  6.509352e-08  \n",
       "1178           0.000000          0.000000     Wp  9.925904e-09  \n",
       "44652          0.000000          0.000000     gg  6.574681e-08  \n",
       "...                 ...               ...    ...           ...  \n",
       "27005          0.000000          0.000000     tt  6.959701e-12  \n",
       "3731           0.000000          0.000000      Z  4.961111e-09  \n",
       "19695          0.000000          0.000000     gg  3.565212e-08  \n",
       "40489          0.000000          0.000000     gg  6.799428e-08  \n",
       "5236           0.000000          0.000000     gg  6.514316e-08  \n",
       "\n",
       "[38282 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BaselineFeaturePipeline = \\\n",
    "    pipeline_maker(Pipeline, steps=[\n",
    "        ('keep_features', KeepFeatures(['photon_n', 'photon_1lead_pt',\n",
    "                                        'photon_1lead_eta', 'photon_1lead_phi',\n",
    "                                        'photon_1lead_E', 'photon_1lead_etcone20',\n",
    "                                        'photon_2lead_pt', 'photon_2lead_eta',\n",
    "                                        'photon_2lead_phi', 'photon_2lead_E',\n",
    "                                        'photon_2lead_etcone20', 'h_mass',\n",
    "                                        'met_et', 'met_phi', 'lep_pt_sum',\n",
    "                                        'lep_phi_sum', 'lep_E_sum', 'lep_theta_sum',\n",
    "                                        'lep_charge_sum', 'lep_ptcone30_sum',\n",
    "                                        'lep_etcone20_sum', 'label', 'weight'])),\n",
    "        ('filna', FillNa(0.))\n",
    "    ])\n",
    "baseline_feature_pipeline = BaselineFeaturePipeline().fit(d_train)\n",
    "baseline_features = baseline_feature_pipeline.transform(d_train)\n",
    "baseline_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_targets(data, targets, drop=None):\n",
    "    flat_target = False\n",
    "    if not isinstance(targets, list):\n",
    "        flat_target = True\n",
    "    to_drop = drop if drop is not None else []\n",
    "    to_drop += targets if not flat_target else [targets]\n",
    "    \n",
    "    Xs = data.drop(columns=to_drop)\n",
    "    ys = data[targets]\n",
    "    \n",
    "    return Xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = RandomForestClassifier(random_state=RANDOM_STATE).fit(*split_targets(baseline_features, \"label\", drop=[\"weight\"]), sample_weight=baseline_features[\"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_importances(feature_importances, feature_names):\n",
    "    return pd.DataFrame(zip(feature_names, feature_importances),\n",
    "                                      columns=[\"feature\", \"score\"]) \\\n",
    "             .set_index(\"feature\") \\\n",
    "             .sort_values(\"score\", axis=\"index\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_feature_importances(ensemble_model):\n",
    "    importances = []\n",
    "    for est in ensemble_model.estimators_:\n",
    "        importances.append(est.steps[-1][1].feature_importances_)\n",
    "    importances = np.vstack(importances)\n",
    "    return np.median(importances, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_importances(model, X_test):\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        feature_importances = model.feature_importances_\n",
    "    elif hasattr(model, \"estimators_\") and hasattr(model.estimators_[0].steps[-1][1], \"feature_importances_\"):\n",
    "        feature_importances = get_ensemble_feature_importances(model)\n",
    "    else:\n",
    "        print(\"Model doesn't seem to provide feature importances. Skip feature importances report\")\n",
    "        return\n",
    "    nice_importances = extract_importances(feature_importances, X_test.columns)\n",
    "    print(\"Feature importances\")\n",
    "    display(nice_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_class_summary(model, feature_pipeline, X_test, y_test, weights=None):\n",
    "    if not hasattr(model, \"classes_\"):\n",
    "        print(\"Model doesn't seem to be a classificator. Skip classification summary report\")\n",
    "        return\n",
    "    classes = model.classes_\n",
    "    labeler = feature_pipeline.named_steps.get(\"labels\")\n",
    "    if labeler is not None:\n",
    "        classes = labeler.transformer.inverse_transform(classes)\n",
    "    print(\"Model classes\")\n",
    "    display(classes)\n",
    "    pred = model.predict(X_test)\n",
    "    conf = confusion_matrix(y_test, pred)\n",
    "    print(\"Confusion matrix, normalized\")\n",
    "    display(conf)\n",
    "    conf = confusion_matrix(y_test, pred, sample_weight=weights)\n",
    "    print(\"-Log confusion matrix of weights\")\n",
    "    display(-np.log(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_descriptive(X_test, y_test, weights=None):\n",
    "    data = pd.concat([X_test, y_test], axis=\"columns\")\n",
    "    if weights is not None:\n",
    "        data = data.assign(weight=weights)\n",
    "        \n",
    "    if \"weight\" in X_test.columns:\n",
    "        weight_sums = data.groupby(\"label\")[\"weight\"].sum()\n",
    "        print(\"Sum of weights\")\n",
    "        display(weight_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(model, feature_pipeline, d_test, drop=None):\n",
    "    X_test, y_test = split_targets(d_test, \"label\", drop=drop)\n",
    "    weights = d_test[\"weight\"]\n",
    "    report_descriptive(X_test, y_test, weights=weights)\n",
    "    report_class_summary(model, feature_pipeline, X_test, y_test, weights=weights)\n",
    "    report_importances(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model has been trained, let's see the report describing the baseline.\n",
    "\n",
    "We have 5 classes and a confusion matrix for them.\n",
    "\n",
    "We also provide confusion matrix for weights in somewhat sophisticated format. Due to weights can differ by orders of magnitude, it is easier to compare logarithms. Since all weights are < 1, it is convenient to remove minus sign close to numbers in the matrix. As a result, the smaller number on the diagonal of the matrix the better.\n",
    "\n",
    "Finally we show feature importances coming from decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['VBF', 'Wp', 'Z', 'gg', 'tt'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, normalized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 717,    3,    8, 1304,   22],\n",
       "       [ 128,   20,   10,  236,   58],\n",
       "       [ 235,    4,   58,  603,   74],\n",
       "       [ 620,    3,   16, 4540,   25],\n",
       "       [ 472,   43,   40,  695,  701]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Log confusion matrix of weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11.93201359, 17.21032844, 16.55685393, 11.31630401, 15.50961559],\n",
       "       [13.75567166, 15.58087654, 16.39603933, 13.1824441 , 14.66865602],\n",
       "       [13.99952044, 18.33243011, 15.26140177, 12.99071183, 15.1836116 ],\n",
       "       [10.34108454, 15.53840086, 13.97303262,  8.35967645, 13.71694805],\n",
       "       [20.34227256, 23.37487264, 23.2164997 , 19.98716491, 20.05360614]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>photon_1lead_pt</th>\n",
       "      <td>0.092880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_E</th>\n",
       "      <td>0.082657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met_et</th>\n",
       "      <td>0.076067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_pt</th>\n",
       "      <td>0.074722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_eta</th>\n",
       "      <td>0.074145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_mass</th>\n",
       "      <td>0.072481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_eta</th>\n",
       "      <td>0.071895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_E</th>\n",
       "      <td>0.071594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_etcone20</th>\n",
       "      <td>0.071456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_phi</th>\n",
       "      <td>0.070805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_phi</th>\n",
       "      <td>0.069921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met_phi</th>\n",
       "      <td>0.068377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_etcone20</th>\n",
       "      <td>0.068230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_pt_sum</th>\n",
       "      <td>0.009915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_charge_sum</th>\n",
       "      <td>0.007175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_E_sum</th>\n",
       "      <td>0.006598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_theta_sum</th>\n",
       "      <td>0.003698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_etcone20_sum</th>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_phi_sum</th>\n",
       "      <td>0.002280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_n</th>\n",
       "      <td>0.001935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lep_ptcone30_sum</th>\n",
       "      <td>0.000739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          score\n",
       "feature                        \n",
       "photon_1lead_pt        0.092880\n",
       "photon_1lead_E         0.082657\n",
       "met_et                 0.076067\n",
       "photon_2lead_pt        0.074722\n",
       "photon_2lead_eta       0.074145\n",
       "h_mass                 0.072481\n",
       "photon_1lead_eta       0.071895\n",
       "photon_2lead_E         0.071594\n",
       "photon_2lead_etcone20  0.071456\n",
       "photon_1lead_phi       0.070805\n",
       "photon_2lead_phi       0.069921\n",
       "met_phi                0.068377\n",
       "photon_1lead_etcone20  0.068230\n",
       "lep_pt_sum             0.009915\n",
       "lep_charge_sum         0.007175\n",
       "lep_E_sum              0.006598\n",
       "lep_theta_sum          0.003698\n",
       "lep_etcone20_sum       0.002431\n",
       "lep_phi_sum            0.002280\n",
       "photon_n               0.001935\n",
       "lep_ptcone30_sum       0.000739"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report(baseline_model, baseline_feature_pipeline, baseline_feature_pipeline.transform(d_test), drop=[\"weight\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently `gg` events are so many, that other events become classified as `gg` just statistically. This means that the dataset is imbalanced, and we should find some approach to target this issue.\n",
    "\n",
    "We also choose subset of features to work with. We pick only significantly relevant features. See the list of them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_by_levels(data, threshold=None, limit=None):\n",
    "    thr_mask = np.array(True)\n",
    "    if threshold is not None:\n",
    "        if isinstance(threshold, dict):\n",
    "            thr_mask = np.all([data[k] > v for k,v in threshold.items()])\n",
    "        else:\n",
    "            thr_mask = np.all(data > threshold, axis=1)\n",
    "    \n",
    "    lim_mask = np.array(True)\n",
    "    if limit is not None:\n",
    "        if isinstance(limit, dict):\n",
    "            lim_mask = np.all([data[k] < v for k,v in limit.items()])\n",
    "        else:\n",
    "            lim_mask = np.all(data < limit, axis=1)\n",
    "            \n",
    "    mask = thr_mask & lim_mask\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_levels(data, threshold=None, limit=None):\n",
    "    mask = mask_by_levels(data, threshold=threshold, limit=limit)\n",
    "    \n",
    "    if np.all(mask):\n",
    "        return data.copy()\n",
    "    else:\n",
    "        return data[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['photon_1lead_pt',\n",
       " 'photon_1lead_E',\n",
       " 'met_et',\n",
       " 'photon_2lead_pt',\n",
       " 'photon_2lead_eta',\n",
       " 'h_mass',\n",
       " 'photon_1lead_eta',\n",
       " 'photon_2lead_E',\n",
       " 'photon_2lead_etcone20',\n",
       " 'photon_1lead_phi',\n",
       " 'photon_2lead_phi',\n",
       " 'met_phi',\n",
       " 'photon_1lead_etcone20']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcolumns = list(filter_by_levels(\n",
    "                extract_importances(\n",
    "                    baseline_model.feature_importances_,\n",
    "                    split_targets(baseline_features, \"label\", drop=[\"weight\"])[0].columns\n",
    "                ),\n",
    "                threshold=0.05\n",
    "             ).index)\n",
    "subcolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WithColumns(TransformerMixin):\n",
    "    def __init__(self, transformer, columns=None):\n",
    "        self.columns = columns\n",
    "        self.transformer = transformer\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.transformer.fit(X[self.columns])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        res = X.copy()\n",
    "        res[self.columns] = self.transformer.transform(res[self.columns])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplaceValues(TransformerMixin):\n",
    "    def __init__(self, mapping):\n",
    "        self.mapping = mapping\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        res = X.replace(self.mapping)\n",
    "        return res\n",
    "# WithColumns(ReplaceValues({\n",
    "#                                 \"VBF\": \"other\",\n",
    "#                                 \"Wp\": \"other\",\n",
    "#                                 \"Z\": \"other\",\n",
    "#                                 \"gg\": \"other\"\n",
    "#                                }), columns=\"label\").fit_transform(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropByLevel(TransformerMixin):\n",
    "    def __init__(self, column, threshold=None, limit=None):\n",
    "        self.column = column\n",
    "        self.threshold = threshold\n",
    "        self.limit = limit\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        mask = mask_by_levels(X[self.column], threshold=self.threshold, limit=self.limit)\n",
    "        \n",
    "        if np.all(mask):\n",
    "            return X.copy()\n",
    "        \n",
    "        return X[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropByValues(TransformerMixin):\n",
    "    def __init__(self, column, values):\n",
    "        self.column = column\n",
    "        self.values = values\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        mask = ~np.any([X[self.column] == v for v in self.values], axis=0)\n",
    "        \n",
    "        if np.all(mask):\n",
    "            return X.copy()\n",
    "        \n",
    "        return X[mask].copy()\n",
    "# DropByValues(\"label\", [\"tt\"]).fit_transform(d_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature processing for next to baseline model, we name it `significant imbalanced model` is a bit more complex. As before, we fill empty values for chosen features with zeros.\n",
    "\n",
    "We also drop `tt`, `Wp` and `Z` events for this step. We try to focus on events that have similar weight per event. `Wp` and `Z` are few but they are very heavy, while `tt` are quite a lot but weight is tiny. It is quite hard to handle such a mixture together.\n",
    "\n",
    "Now we end up with `gg` and `VBF` events. The dataset is still imbalanced from the number of events perspective, but at the same time we can bother less about their weights.\n",
    "\n",
    "As a part of feature processing, we also drop negative weights. That's just a technical issue, because the algorithm we are going to apply can't handle negative weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photon_1lead_pt</th>\n",
       "      <th>photon_1lead_E</th>\n",
       "      <th>met_et</th>\n",
       "      <th>photon_2lead_pt</th>\n",
       "      <th>photon_2lead_eta</th>\n",
       "      <th>h_mass</th>\n",
       "      <th>photon_1lead_eta</th>\n",
       "      <th>photon_2lead_E</th>\n",
       "      <th>photon_2lead_etcone20</th>\n",
       "      <th>photon_1lead_phi</th>\n",
       "      <th>photon_2lead_phi</th>\n",
       "      <th>met_phi</th>\n",
       "      <th>photon_1lead_etcone20</th>\n",
       "      <th>label</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34762</th>\n",
       "      <td>68985.805</td>\n",
       "      <td>85216.230</td>\n",
       "      <td>30061.690</td>\n",
       "      <td>51873.760</td>\n",
       "      <td>-0.020217</td>\n",
       "      <td>118622.77</td>\n",
       "      <td>0.673179</td>\n",
       "      <td>51884.363</td>\n",
       "      <td>-54.641132</td>\n",
       "      <td>-2.755656</td>\n",
       "      <td>0.261481</td>\n",
       "      <td>-0.911852</td>\n",
       "      <td>-33.08661</td>\n",
       "      <td>1</td>\n",
       "      <td>6.426950e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47589</th>\n",
       "      <td>66244.650</td>\n",
       "      <td>68949.734</td>\n",
       "      <td>9151.307</td>\n",
       "      <td>49499.246</td>\n",
       "      <td>-0.664182</td>\n",
       "      <td>129391.59</td>\n",
       "      <td>0.284815</td>\n",
       "      <td>60824.562</td>\n",
       "      <td>-703.480700</td>\n",
       "      <td>-0.899317</td>\n",
       "      <td>2.492585</td>\n",
       "      <td>0.882567</td>\n",
       "      <td>-430.34076</td>\n",
       "      <td>1</td>\n",
       "      <td>6.509352e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44652</th>\n",
       "      <td>62168.310</td>\n",
       "      <td>103743.570</td>\n",
       "      <td>81357.300</td>\n",
       "      <td>43533.900</td>\n",
       "      <td>0.573396</td>\n",
       "      <td>133043.72</td>\n",
       "      <td>-1.100176</td>\n",
       "      <td>50888.734</td>\n",
       "      <td>-355.123320</td>\n",
       "      <td>-2.316379</td>\n",
       "      <td>2.214298</td>\n",
       "      <td>-0.120469</td>\n",
       "      <td>-257.24194</td>\n",
       "      <td>1</td>\n",
       "      <td>6.574681e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29709</th>\n",
       "      <td>56140.140</td>\n",
       "      <td>92557.170</td>\n",
       "      <td>59095.723</td>\n",
       "      <td>49639.758</td>\n",
       "      <td>0.142135</td>\n",
       "      <td>134930.78</td>\n",
       "      <td>-1.085008</td>\n",
       "      <td>50142.023</td>\n",
       "      <td>-722.904050</td>\n",
       "      <td>1.459849</td>\n",
       "      <td>-2.128604</td>\n",
       "      <td>-0.804518</td>\n",
       "      <td>-515.87780</td>\n",
       "      <td>1</td>\n",
       "      <td>6.081813e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11376</th>\n",
       "      <td>56304.918</td>\n",
       "      <td>69706.420</td>\n",
       "      <td>5357.768</td>\n",
       "      <td>51354.156</td>\n",
       "      <td>-0.455490</td>\n",
       "      <td>118769.27</td>\n",
       "      <td>0.676951</td>\n",
       "      <td>56774.160</td>\n",
       "      <td>-774.800000</td>\n",
       "      <td>2.270618</td>\n",
       "      <td>-0.818975</td>\n",
       "      <td>2.244862</td>\n",
       "      <td>-278.63430</td>\n",
       "      <td>1</td>\n",
       "      <td>6.155636e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32745</th>\n",
       "      <td>123812.510</td>\n",
       "      <td>124740.280</td>\n",
       "      <td>55756.870</td>\n",
       "      <td>33976.465</td>\n",
       "      <td>-0.132365</td>\n",
       "      <td>130749.42</td>\n",
       "      <td>0.122344</td>\n",
       "      <td>34274.540</td>\n",
       "      <td>-307.793000</td>\n",
       "      <td>1.774965</td>\n",
       "      <td>-1.117429</td>\n",
       "      <td>-2.609147</td>\n",
       "      <td>-236.87490</td>\n",
       "      <td>0</td>\n",
       "      <td>3.267510e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25881</th>\n",
       "      <td>73171.550</td>\n",
       "      <td>77066.600</td>\n",
       "      <td>44342.586</td>\n",
       "      <td>69011.670</td>\n",
       "      <td>0.984790</td>\n",
       "      <td>115833.22</td>\n",
       "      <td>0.324857</td>\n",
       "      <td>105269.270</td>\n",
       "      <td>-502.582800</td>\n",
       "      <td>1.761882</td>\n",
       "      <td>-2.675597</td>\n",
       "      <td>-0.624818</td>\n",
       "      <td>-667.40283</td>\n",
       "      <td>0</td>\n",
       "      <td>1.104680e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19695</th>\n",
       "      <td>62460.710</td>\n",
       "      <td>67644.390</td>\n",
       "      <td>74117.960</td>\n",
       "      <td>48761.650</td>\n",
       "      <td>-0.666147</td>\n",
       "      <td>126094.12</td>\n",
       "      <td>0.404643</td>\n",
       "      <td>59986.727</td>\n",
       "      <td>-996.092960</td>\n",
       "      <td>-2.093862</td>\n",
       "      <td>1.519702</td>\n",
       "      <td>0.057860</td>\n",
       "      <td>-138.29385</td>\n",
       "      <td>1</td>\n",
       "      <td>3.565212e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40489</th>\n",
       "      <td>66830.560</td>\n",
       "      <td>67717.870</td>\n",
       "      <td>17952.191</td>\n",
       "      <td>45487.150</td>\n",
       "      <td>-0.942891</td>\n",
       "      <td>134209.08</td>\n",
       "      <td>0.162774</td>\n",
       "      <td>67250.305</td>\n",
       "      <td>-70.243450</td>\n",
       "      <td>-1.102934</td>\n",
       "      <td>1.962060</td>\n",
       "      <td>-1.235665</td>\n",
       "      <td>-623.46350</td>\n",
       "      <td>1</td>\n",
       "      <td>6.799428e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>89904.150</td>\n",
       "      <td>97593.580</td>\n",
       "      <td>36336.914</td>\n",
       "      <td>75717.040</td>\n",
       "      <td>1.006672</td>\n",
       "      <td>128631.44</td>\n",
       "      <td>0.410700</td>\n",
       "      <td>117433.766</td>\n",
       "      <td>-99.001884</td>\n",
       "      <td>2.252704</td>\n",
       "      <td>-2.517539</td>\n",
       "      <td>0.124677</td>\n",
       "      <td>-528.38260</td>\n",
       "      <td>1</td>\n",
       "      <td>6.514316e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25841 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       photon_1lead_pt  photon_1lead_E     met_et  photon_2lead_pt  \\\n",
       "34762        68985.805       85216.230  30061.690        51873.760   \n",
       "47589        66244.650       68949.734   9151.307        49499.246   \n",
       "44652        62168.310      103743.570  81357.300        43533.900   \n",
       "29709        56140.140       92557.170  59095.723        49639.758   \n",
       "11376        56304.918       69706.420   5357.768        51354.156   \n",
       "...                ...             ...        ...              ...   \n",
       "32745       123812.510      124740.280  55756.870        33976.465   \n",
       "25881        73171.550       77066.600  44342.586        69011.670   \n",
       "19695        62460.710       67644.390  74117.960        48761.650   \n",
       "40489        66830.560       67717.870  17952.191        45487.150   \n",
       "5236         89904.150       97593.580  36336.914        75717.040   \n",
       "\n",
       "       photon_2lead_eta     h_mass  photon_1lead_eta  photon_2lead_E  \\\n",
       "34762         -0.020217  118622.77          0.673179       51884.363   \n",
       "47589         -0.664182  129391.59          0.284815       60824.562   \n",
       "44652          0.573396  133043.72         -1.100176       50888.734   \n",
       "29709          0.142135  134930.78         -1.085008       50142.023   \n",
       "11376         -0.455490  118769.27          0.676951       56774.160   \n",
       "...                 ...        ...               ...             ...   \n",
       "32745         -0.132365  130749.42          0.122344       34274.540   \n",
       "25881          0.984790  115833.22          0.324857      105269.270   \n",
       "19695         -0.666147  126094.12          0.404643       59986.727   \n",
       "40489         -0.942891  134209.08          0.162774       67250.305   \n",
       "5236           1.006672  128631.44          0.410700      117433.766   \n",
       "\n",
       "       photon_2lead_etcone20  photon_1lead_phi  photon_2lead_phi   met_phi  \\\n",
       "34762             -54.641132         -2.755656          0.261481 -0.911852   \n",
       "47589            -703.480700         -0.899317          2.492585  0.882567   \n",
       "44652            -355.123320         -2.316379          2.214298 -0.120469   \n",
       "29709            -722.904050          1.459849         -2.128604 -0.804518   \n",
       "11376            -774.800000          2.270618         -0.818975  2.244862   \n",
       "...                      ...               ...               ...       ...   \n",
       "32745            -307.793000          1.774965         -1.117429 -2.609147   \n",
       "25881            -502.582800          1.761882         -2.675597 -0.624818   \n",
       "19695            -996.092960         -2.093862          1.519702  0.057860   \n",
       "40489             -70.243450         -1.102934          1.962060 -1.235665   \n",
       "5236              -99.001884          2.252704         -2.517539  0.124677   \n",
       "\n",
       "       photon_1lead_etcone20  label        weight  \n",
       "34762              -33.08661      1  6.426950e-08  \n",
       "47589             -430.34076      1  6.509352e-08  \n",
       "44652             -257.24194      1  6.574681e-08  \n",
       "29709             -515.87780      1  6.081813e-08  \n",
       "11376             -278.63430      1  6.155636e-08  \n",
       "...                      ...    ...           ...  \n",
       "32745             -236.87490      0  3.267510e-09  \n",
       "25881             -667.40283      0  1.104680e-08  \n",
       "19695             -138.29385      1  3.565212e-08  \n",
       "40489             -623.46350      1  6.799428e-08  \n",
       "5236              -528.38260      1  6.514316e-08  \n",
       "\n",
       "[25841 rows x 15 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SignificantFeaturePipeline = \\\n",
    "    pipeline_maker(Pipeline, steps=[\n",
    "        ('keep_features', KeepFeatures(subcolumns + [\"label\", \"weight\"])),\n",
    "        ('filna', FillNa(0.)),\n",
    "        ('drop_tt', DropByValues(\"label\", [\"tt\", \"Wp\", \"Z\"])),\n",
    "        ('drop_neg_weight', DropByLevel([\"weight\"], threshold=0)),\n",
    "        ('labels', WithColumns(LabelEncoder(), columns=\"label\"))\n",
    "    ])\n",
    "significant_feature_pipeline = SignificantFeaturePipeline().fit(d_train)\n",
    "significant_features = significant_feature_pipeline.transform(d_train)\n",
    "significant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(significant_features[\"weight\"] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the reference about usage of [bagging for imbalanced datasets](https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/) we focus on the model of Easy Ensemble. It is an ensemble model, where AdaBoost (a variant of BDT) is used as a base estimator. The goal is to downsample major class in order to balance the trainig sample.\n",
    "\n",
    "To avoid throwing out the data we train 6 different AdaBoosts on different samples, where minority class is always entirely included, while events from majority class are downsampled to fit number of events in the minority class.\n",
    "\n",
    "After 6 different base estimators have been trained, the voting procedure decides on the prediction for the specific test event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedAdaBoost(AdaBoostClassifier):\n",
    "    def __init__(self,\n",
    "                 base_estimator=None, *,\n",
    "                 n_estimators=50,\n",
    "                 learning_rate=1.,\n",
    "                 algorithm='SAMME.R',\n",
    "                 random_state=None, weights_column=None):\n",
    "\n",
    "        super().__init__(\n",
    "            base_estimator=base_estimator,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            random_state=random_state)\n",
    "        self.weights_column = weights_column\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        super().fit(np.delete(X, self.weights_column, 1), y, sample_weight=X[:, self.weights_column])\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return super().predict(np.delete(X, self.weights_column, 1))\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return super().predict_proba(np.delete(X, self.weights_column, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_imbal_model = EasyEnsembleClassifier( \\\n",
    "                                          n_estimators=6,\n",
    "                                          base_estimator=WeightedAdaBoost(weights_column=list(split_targets(significant_features, \"label\")[0].columns).index(\"weight\")),\n",
    "                                          random_state=RANDOM_STATE,\n",
    "                                          sampling_strategy=\"not minority\",\n",
    "                                          replacement=False\n",
    "                                         ) \\\n",
    "                   .fit(*split_targets(significant_features, \"label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a report following the same structure as we had for the baseline model.\n",
    "\n",
    "Here we have 2 classes with a simple confusion matrix. It shows that we still didn't manage to fight the imbalance.\n",
    "\n",
    "Since here we have ensemble of BDTs, as feature importance we show median of scores per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.000019\n",
       "1    0.000269\n",
       "Name: weight, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['VBF', 'gg'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, normalized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  56, 1958],\n",
       "       [  42, 5049]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Log confusion matrix of weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[14.35249688, 10.89898206],\n",
       "       [13.00675829,  8.22907426]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>photon_1lead_pt</th>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_eta</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_eta</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_pt</th>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_E</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met_et</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_E</th>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_mass</th>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>met_phi</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_etcone20</th>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_2lead_phi</th>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_phi</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photon_1lead_etcone20</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       score\n",
       "feature                     \n",
       "photon_1lead_pt         0.21\n",
       "photon_2lead_eta        0.14\n",
       "photon_1lead_eta        0.14\n",
       "photon_2lead_pt         0.09\n",
       "photon_1lead_E          0.08\n",
       "met_et                  0.08\n",
       "photon_2lead_E          0.07\n",
       "h_mass                  0.06\n",
       "met_phi                 0.05\n",
       "photon_2lead_etcone20   0.03\n",
       "photon_2lead_phi        0.03\n",
       "photon_1lead_phi        0.00\n",
       "photon_1lead_etcone20   0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report(sign_imbal_model, significant_feature_pipeline, significant_feature_pipeline.transform(d_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
